{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "87273e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from datetime import datetime\n",
    "from typing import Tuple\n",
    "\n",
    "from torch.nn import Module\n",
    "from torch.nn import KLDivLoss, CrossEntropyLoss, CosineEmbeddingLoss\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9bd6d6",
   "metadata": {},
   "source": [
    "### Loading Teacher model ---> CLIP Image Extractor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "88cbfadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 87,849,216\n",
      "Input resolution: 224\n"
     ]
    }
   ],
   "source": [
    "import clip\n",
    "\n",
    "model_name = \"ViT-B/32\"\n",
    "\n",
    "# model is the torch model.\n",
    "# preprocess function is for image preprocessing.\n",
    "\n",
    "model, preprocess = clip.load(model_name)\n",
    "\n",
    "# Get only the visual model\n",
    "teacher_model = model.visual\n",
    "input_resolution = model.visual.input_resolution\n",
    "\n",
    "print(\n",
    "    \"Model parameters:\",\n",
    "    f\"{np.sum([int(np.prod(p.shape)) for p in model.visual.parameters()]):,}\",\n",
    ")\n",
    "print(\"Input resolution:\", input_resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7896653c",
   "metadata": {},
   "source": [
    "### Instantiating Student model \n",
    "\n",
    "[VisionTransformer](https://github.com/openai/CLIP/blob/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1/clip/model.py#L206)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a1340820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 12,044,160\n"
     ]
    }
   ],
   "source": [
    "from clip.model import VisionTransformer\n",
    "from clip.model import convert_weights # Make them float16\n",
    "# Set Student Configuration\n",
    "\n",
    "patch_size = 32\n",
    "width = 384\n",
    "layers = 6\n",
    "heads = 12\n",
    "output_dim = 512\n",
    "\n",
    "student_model = VisionTransformer(\n",
    "    input_resolution=input_resolution,\n",
    "    patch_size=patch_size,\n",
    "    width=width,\n",
    "    layers=layers,\n",
    "    heads=heads,\n",
    "    output_dim=output_dim,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "convert_weights(student_model)\n",
    "\n",
    "\n",
    "print(\n",
    "    \"Model parameters:\",\n",
    "    f\"{np.sum([int(np.prod(p.shape)) for p in student_model.parameters()]):,}\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6debb0c",
   "metadata": {},
   "source": [
    "### Load the WIT Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c6383d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset cifar10 (/home/ecbm4040/.cache/huggingface/datasets/cifar10/plain_text/1.0.0/447d6ec4733dddd1ce3bb577c7166b986eaa4c538dcd9e805ba61f35674a9de4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f34f879a2ce64804a97258bb4ab7c96e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from functools import partial\n",
    "import io\n",
    "import urllib\n",
    "\n",
    "import PIL.Image\n",
    "\n",
    "from datasets import load_dataset\n",
    "from datasets.utils.file_utils import get_datasets_user_agent\n",
    "\n",
    "\n",
    "def fetch_single_image(image_url, timeout=None, retries=0):\n",
    "    for _ in range(retries + 1):\n",
    "        try:\n",
    "            request = urllib.request.Request(\n",
    "                image_url,\n",
    "                data=None,\n",
    "                headers={\"user-agent\": get_datasets_user_agent()},\n",
    "            )\n",
    "            with urllib.request.urlopen(request, timeout=timeout) as req:\n",
    "                image = PIL.Image.open(io.BytesIO(req.read()))\n",
    "            break\n",
    "        except Exception:\n",
    "            image = None\n",
    "    return image\n",
    "\n",
    "\n",
    "def fetch_images(batch, num_threads, timeout=None, retries=0):\n",
    "    fetch_single_image_with_args = partial(\n",
    "        fetch_single_image, timeout=timeout, retries=retries\n",
    "    )\n",
    "    with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        batch[\"image\"] = list(\n",
    "            executor.map(fetch_single_image_with_args, batch[\"image_url\"])\n",
    "        )\n",
    "    return batch\n",
    "\n",
    "\n",
    "num_threads = 20\n",
    "dset = load_dataset(\"cifar10\")\n",
    "# dset = dset.map(\n",
    "#     fetch_images, batched=True, batch_size=100, fn_kwargs={\"num_threads\": num_threads}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "035ee833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.RandomCrop(224),\n",
    "                #transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "cifar100 = torchvision.datasets.CIFAR100('data/',download=True,train=True,transform=transform)\n",
    "train_dataloader = torch.utils.data.DataLoader(cifar100,\n",
    "                                          batch_size=4,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "609fd86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistillationTrainer:\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.teacher = teacher_model\n",
    "        self.student = student_model\n",
    "        self.preprocess = preprocess\n",
    "        self.train_dataloader = train_dataloader\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.teacher = self.teacher.to(self.device)\n",
    "        self.student = self.student.to(self.device)\n",
    "        self.teacher.eval()\n",
    "\n",
    "        self.epochs = 30\n",
    "        self.start_epoch = 1\n",
    "\n",
    "        # set up optimizer\n",
    "        self.optimizer = Adam(self.student.parameters())\n",
    "\n",
    "        # Set up LR Scheduler\n",
    "        self.lr_scheduler = ReduceLROnPlateau(self.optimizer, \"min\")\n",
    "\n",
    "    def compute_loss(self, images, return_outputs=False):\n",
    "        images = images.to(self.device).half()\n",
    "        import pdb; pdb.set_trace()\n",
    "        outputs_student = self.student(images)\n",
    "\n",
    "        # compute teacher output\n",
    "        with torch.no_grad():\n",
    "            outputs_teacher = self.teacher(images)\n",
    "\n",
    "        # assert size\n",
    "        assert outputs_student.size() == outputs_teacher.size()\n",
    "\n",
    "        # Soften probabilities and compute distillation loss\n",
    "\n",
    "        # KL Divergence Loss\n",
    "        kl_loss = KLDivLoss(reduction=\"batchmean\")\n",
    "        loss = kl_loss(outputs_student, outputs_teacher)\n",
    "        # Cosine loss\n",
    "        loss = loss + CosineEmbeddingLoss()(\n",
    "            outputs_teacher, outputs_student, torch.ones(outputs_teacher.size()[0]).to(self.device)\n",
    "        )\n",
    "        print(f\"Loss is {loss}\")\n",
    "        return (loss, outputs_student) if return_outputs else loss\n",
    "\n",
    "    def train(self):\n",
    "        for epoch in range(self.start_epoch, self.epochs + 1):\n",
    "            loss_value = self._train_epoch(epoch)\n",
    "            print(f\"KLD-CosineLoss after {epoch} Epoch is {loss_value}\")\n",
    "\n",
    "    def _train_epoch(self, epoch):\n",
    "        loss_value = 0\n",
    "        for batch_idx, (images, _) in enumerate(self.train_dataloader):\n",
    "            \n",
    "            loss = self.compute_loss( images)\n",
    "            print(loss)\n",
    "            loss_value += loss\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            self.optimizer.step()\n",
    "            \n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f\"Loss after {batch_idx} Batch is {loss_value/(batch_idx+1)} \")\n",
    "\n",
    "        return loss_value.detach().cpu().numpy() / len(self.train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "63c467ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Trainer = DistillationTrainer(\n",
    "    teacher_model=teacher_model,\n",
    "    student_model=student_model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    preprocess = preprocess,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c83373ae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is -59.8125\n",
      "tensor(-59.8125, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss after 0 Batch is -59.8125 \n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss after 10 Batch is nan \n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss after 20 Batch is nan \n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss after 30 Batch is nan \n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss after 40 Batch is nan \n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss after 50 Batch is nan \n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss after 60 Batch is nan \n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss after 70 Batch is nan \n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss after 80 Batch is nan \n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss after 90 Batch is nan \n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss after 100 Batch is nan \n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss after 110 Batch is nan \n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "Loss is nan\n",
      "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-443d7d661a57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-40-f0d9626465a7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"KLD-CosineLoss after {epoch} Epoch is {loss_value}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-f0d9626465a7>\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mloss_value\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-f0d9626465a7>\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, images, return_outputs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhalf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0moutputs_student\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstudent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130cf32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in train_dataloader:\n",
    "    print(x[0].shape,x[1].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3c9953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(\n",
    "#     {\n",
    "#         \"distilbert\": student_distil_bert.state_dict(),\n",
    "#     },\n",
    "#     f\"distiled_distilbert_sst2_{datetime.now():%Y-%m-%d_%H-%M-%S%z}.pt\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4217207",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9bc4f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c000c30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872f9943",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96860ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6fcaaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
