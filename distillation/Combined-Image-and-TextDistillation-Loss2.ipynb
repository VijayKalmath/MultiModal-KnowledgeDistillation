{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87273e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from datetime import datetime\n",
    "from typing import Tuple\n",
    "from torch import nn\n",
    "from torch.nn import Module\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import KLDivLoss, CrossEntropyLoss, CosineEmbeddingLoss, MSELoss\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64163f3",
   "metadata": {},
   "source": [
    "###  Combined Image and TextDistillation with Bigger Dataset with Loss2\n",
    "\n",
    "Loss2 Definition : (MSE Loss + Cosine Loss + Constrastive Loss )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bc415f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_name = \"loss2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9bd6d6",
   "metadata": {},
   "source": [
    "### Loading Teacher models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88cbfadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "\n",
    "model_name = \"ViT-B/32\"\n",
    "\n",
    "model, preprocess = clip.load(model_name)\n",
    "\n",
    "visual_teacher_model = model.visual\n",
    "text_teacher_model = model.transformer\n",
    "\n",
    "\n",
    "input_resolution = model.visual.input_resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7896653c",
   "metadata": {},
   "source": [
    "### Instantiating Student models\n",
    "\n",
    "[VisionTransformer](https://github.com/openai/CLIP/blob/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1/clip/model.py#L206)\n",
    "[Transformer](https://github.com/openai/CLIP/blob/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1/clip/model.py#L195)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1340820",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clip.model import Transformer, VisionTransformer\n",
    "from clip.model import convert_weights  # Make them float16\n",
    "\n",
    "# Set Student Configuration\n",
    "\n",
    "patch_size = 32\n",
    "width = 384\n",
    "layers = 6\n",
    "heads = 12\n",
    "output_dim = 512\n",
    "\n",
    "visual_student_model = VisionTransformer(\n",
    "    input_resolution=input_resolution,\n",
    "    patch_size=patch_size,\n",
    "    width=width,\n",
    "    layers=layers,\n",
    "    heads=heads,\n",
    "    output_dim=output_dim,\n",
    ")\n",
    "\n",
    "width = 512\n",
    "layers = 6\n",
    "heads = 8  # More Number of Heads\n",
    "\n",
    "\n",
    "def build_attention_mask():\n",
    "    context_length = 77\n",
    "    mask = torch.empty(context_length, context_length)\n",
    "    mask.fill_(float(\"-inf\"))\n",
    "    mask.triu_(1)  # zero out the lower diagonal\n",
    "    return mask\n",
    "\n",
    "\n",
    "text_student_model = Transformer(\n",
    "    width=width, layers=layers, heads=heads, attn_mask=build_attention_mask()\n",
    ")\n",
    "\n",
    "\n",
    "convert_weights(visual_student_model)\n",
    "convert_weights(text_student_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c600678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_text(transformer, text):\n",
    "\n",
    "    x = model.token_embedding(text).type(model.dtype)  # [batch_size, n_ctx, d_model]\n",
    "\n",
    "    x = x + model.positional_embedding.type(model.dtype)\n",
    "    x = x.permute(1, 0, 2)  # NLD -> LND\n",
    "\n",
    "    x = transformer(x)\n",
    "\n",
    "    x = x.permute(1, 0, 2)  # LND -> NLD\n",
    "    x = model.ln_final(x).type(model.dtype)\n",
    "\n",
    "    # x.shape = [batch_size, n_ctx, transformer.width]\n",
    "    # take features from the eot embedding (eot_token is the highest number in each sequence)\n",
    "    x = x[torch.arange(x.shape[0]), text.argmax(dim=-1)] @ model.text_projection\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c4d724e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProjectionHead(nn.Module):\n",
    "    def __init__(self, embedding_dim=512, projection_dim=512, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.projection = nn.Linear(embedding_dim, projection_dim)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.fc = nn.Linear(projection_dim, projection_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(projection_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        projected = self.projection(x)\n",
    "        x = self.gelu(projected)\n",
    "        x = self.fc(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x + projected\n",
    "        x = self.layer_norm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6debb0c",
   "metadata": {},
   "source": [
    "### Load the Conceptual Captions Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93d87c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from concurrent.futures import ThreadPoolExecutor\n",
    "# from functools import partial\n",
    "# import io\n",
    "# import urllib\n",
    "\n",
    "# import PIL.Image\n",
    "\n",
    "# from datasets import load_dataset\n",
    "# from datasets.utils.file_utils import get_datasets_user_agent\n",
    "\n",
    "\n",
    "# def fetch_single_image(image_url, timeout=None, retries=0):\n",
    "#     for _ in range(retries + 1):\n",
    "#         try:\n",
    "#             request = urllib.request.Request(\n",
    "#                 image_url,\n",
    "#                 data=None,\n",
    "#                 headers={\"user-agent\": get_datasets_user_agent()},\n",
    "#             )\n",
    "#             with urllib.request.urlopen(request, timeout=timeout) as req:\n",
    "#                 image = PIL.Image.open(io.BytesIO(req.read()))\n",
    "#             break\n",
    "#         except Exception:\n",
    "#             image = None\n",
    "#     return image\n",
    "\n",
    "\n",
    "# def fetch_images(batch, num_threads, timeout=None, retries=0):\n",
    "#     fetch_single_image_with_args = partial(\n",
    "#         fetch_single_image, timeout=timeout, retries=retries\n",
    "#     )\n",
    "#     with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "#         batch[\"image\"] = list(\n",
    "#             executor.map(fetch_single_image_with_args, batch[\"image_url\"])\n",
    "#         )\n",
    "#     return batch\n",
    "\n",
    "\n",
    "# num_threads = 8\n",
    "# dset = load_dataset(\"conceptual_captions\",split='train[:50000]')#,cache_dir = \"./data/ConceptualCaptions\")\n",
    "\n",
    "\n",
    "# dset = dset.filter(lambda example: len(example[\"caption\"]) < 75)\n",
    "\n",
    "# dset = dset.map(\n",
    "#     fetch_images, batched=True, batch_size=100, fn_kwargs={\"num_threads\": num_threads}\n",
    "# )\n",
    "\n",
    "\n",
    "# dset = dset.remove_columns(\"image_url\")\n",
    "# # dset = dset.filter(lambda example : example[\"image\"] is not None)\n",
    "\n",
    "# # dset.save_to_disk(\"./data/processed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0948606c",
   "metadata": {},
   "source": [
    "#### Convert Dataset into Torch Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0ef402f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_from_disk\n",
    "\n",
    "dset = load_from_disk(\"./data/processed\")\n",
    "\n",
    "\n",
    "def transform_func(examples):\n",
    "    examples[\"image\"] = [preprocess(img) for img in examples[\"image\"]]\n",
    "    return examples\n",
    "\n",
    "\n",
    "dset = dset.with_transform(transform_func)\n",
    "\n",
    "train_dataloader = DataLoader(dset, batch_size=16, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05ca43cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['caption', 'image'],\n",
       "    num_rows: 7012\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "609fd86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistillationTrainer:\n",
    "    def __init__(self, *args, **kwargs):\n",
    "\n",
    "        self.visual_teacher = visual_teacher_model\n",
    "        self.text_teacher = text_teacher_model\n",
    "\n",
    "        self.visual_student = visual_student_model\n",
    "        self.text_student = text_student_model\n",
    "\n",
    "        self.image_projection = ProjectionHead().half()\n",
    "        self.text_projection = ProjectionHead().half()\n",
    "        self.temperature = 1\n",
    "\n",
    "        self.train_dataloader = train_dataloader\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.visual_teacher = self.visual_teacher.to(self.device)\n",
    "        self.text_teacher = self.text_teacher.to(self.device)\n",
    "        self.visual_student = self.visual_student.to(self.device)\n",
    "        self.text_student = self.text_student.to(self.device)\n",
    "        self.image_projection = self.image_projection.to(self.device)\n",
    "        self.text_projection = self.text_projection.to(self.device)\n",
    "\n",
    "        self.visual_teacher.eval()\n",
    "        self.text_teacher.eval()\n",
    "\n",
    "        self.epochs = 30\n",
    "        self.start_epoch = 1\n",
    "\n",
    "        # set up optimizer\n",
    "        self.optimizer = SGD(\n",
    "            list(self.visual_student.parameters())\n",
    "            + list(self.text_student.parameters()),\n",
    "            lr=0.001,\n",
    "        )\n",
    "\n",
    "    def compute_loss(self, images, texts, return_outputs=False):\n",
    "        texts = clip.tokenize(texts)\n",
    "\n",
    "        texts = texts.to(self.device)\n",
    "\n",
    "        images = images.to(self.device).half()\n",
    "\n",
    "        visual_outputs_student = self.visual_student(images)\n",
    "        text_outputs_student = encode_text(self.text_student, texts)\n",
    "\n",
    "        # compute teacher output\n",
    "        with torch.no_grad():\n",
    "            visual_outputs_teacher = self.visual_teacher(images)\n",
    "            text_outputs_teacher = model.encode_text(texts)\n",
    "\n",
    "        # assert size\n",
    "        assert visual_outputs_student.size() == visual_outputs_teacher.size()\n",
    "        assert text_outputs_student.size() == text_outputs_teacher.size()\n",
    "\n",
    "        # MSE Loss between the embeddings\n",
    "\n",
    "        mse_loss = MSELoss()\n",
    "        image_mse_loss = mse_loss(visual_outputs_student, visual_outputs_teacher)\n",
    "        text_mse_loss = mse_loss(text_outputs_student, text_outputs_teacher)\n",
    "\n",
    "        # Cosine Loss\n",
    "        image_cosine_loss = CosineEmbeddingLoss()(\n",
    "            visual_outputs_teacher,\n",
    "            visual_outputs_student,\n",
    "            torch.ones(visual_outputs_teacher.size()[0]).to(self.device),\n",
    "        )\n",
    "\n",
    "        text_cosine_loss = CosineEmbeddingLoss()(\n",
    "            text_outputs_teacher,\n",
    "            text_outputs_student,\n",
    "            torch.ones(text_outputs_teacher.size()[0]).to(self.device),\n",
    "        )\n",
    "\n",
    "        # Push visual_outputs_student and text_outputs_student closer\n",
    "        image_embeddings = self.image_projection(visual_outputs_student)\n",
    "        text_embeddings = self.text_projection(text_outputs_student)\n",
    "\n",
    "        logits = (text_embeddings @ image_embeddings.T) / self.temperature\n",
    "\n",
    "        images_similarity = image_embeddings @ image_embeddings.T\n",
    "        texts_similarity = text_embeddings @ text_embeddings.T\n",
    "\n",
    "        targets = F.softmax(\n",
    "            (images_similarity + texts_similarity) / 2 * self.temperature, dim=-1\n",
    "        )\n",
    "\n",
    "        texts_loss = self.cross_entropy(logits, targets, reduction=\"none\")\n",
    "        images_loss = self.cross_entropy(logits.T, targets.T, reduction=\"none\")\n",
    "        con_loss = (images_loss + texts_loss) / 2.0\n",
    "        con_loss = con_loss.mean()\n",
    "\n",
    "        loss = (\n",
    "            image_mse_loss\n",
    "            + text_mse_loss\n",
    "            + image_cosine_loss\n",
    "            + text_cosine_loss\n",
    "            + con_loss\n",
    "        )\n",
    "\n",
    "        loss = loss / 5\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def cross_entropy(self, preds, targets, reduction=\"none\"):\n",
    "        log_softmax = nn.LogSoftmax(dim=-1)\n",
    "        loss = (-targets * log_softmax(preds)).sum(1)\n",
    "        if reduction == \"none\":\n",
    "            return loss\n",
    "        elif reduction == \"mean\":\n",
    "            return loss.mean()\n",
    "\n",
    "    def train(self):\n",
    "        for epoch in range(self.start_epoch, self.epochs + 1):\n",
    "            print(f\"Starting Epoch {epoch} ------------------------------------------\")\n",
    "            loss_value = self._train_epoch(epoch)\n",
    "            print(f\"Combined Loss Value after {epoch} Epoch is {loss_value}\")\n",
    "\n",
    "    def _train_epoch(self, epoch):\n",
    "        loss_value = 0\n",
    "        for batch_idx, data in enumerate(self.train_dataloader):\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            texts = data[\"caption\"]\n",
    "            images = data[\"image\"]\n",
    "\n",
    "            loss = self.compute_loss(images, texts)\n",
    "\n",
    "            loss_value += loss\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            self.optimizer.step()\n",
    "\n",
    "            if batch_idx % 100 == 0:\n",
    "                print(\n",
    "                    f\"Loss after {batch_idx}/{len(self.train_dataloader)} Batch is {loss_value/(batch_idx+1)} \"\n",
    "                )\n",
    "\n",
    "        return loss_value.detach().cpu().numpy() / len(self.train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63c467ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Trainer = DistillationTrainer(\n",
    "    visual_teacher_model=visual_teacher_model,\n",
    "    text_teacher_model=text_teacher_model,\n",
    "    text_student_model=text_student_model,\n",
    "    visual_student_model=visual_student_model,\n",
    "    train_dataloader=train_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c83373ae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1 ------------------------------------------\n",
      "Loss after 0/439 Batch is 3.802734375 \n",
      "Loss after 100/439 Batch is 2.73046875 \n",
      "Loss after 200/439 Batch is 2.310546875 \n",
      "Loss after 300/439 Batch is 2.09375 \n",
      "Loss after 400/439 Batch is 1.9541015625 \n",
      "Combined Loss Value after 1 Epoch is 1.9145785876993167\n",
      "Starting Epoch 2 ------------------------------------------\n",
      "Loss after 0/439 Batch is 1.3642578125 \n",
      "Loss after 100/439 Batch is 1.45703125 \n",
      "Loss after 200/439 Batch is 1.421875 \n",
      "Loss after 300/439 Batch is 1.39453125 \n",
      "Loss after 400/439 Batch is 1.373046875 \n",
      "Combined Loss Value after 2 Epoch is 1.356492027334852\n",
      "Starting Epoch 3 ------------------------------------------\n",
      "Loss after 0/439 Batch is 1.2216796875 \n",
      "Loss after 100/439 Batch is 1.2431640625 \n",
      "Loss after 200/439 Batch is 1.220703125 \n",
      "Loss after 300/439 Batch is 1.2177734375 \n",
      "Loss after 400/439 Batch is 1.2080078125 \n",
      "Combined Loss Value after 3 Epoch is 1.1993166287015946\n",
      "Starting Epoch 4 ------------------------------------------\n",
      "Loss after 0/439 Batch is 1.033203125 \n",
      "Loss after 100/439 Batch is 1.140625 \n",
      "Loss after 200/439 Batch is 1.12890625 \n",
      "Loss after 300/439 Batch is 1.11328125 \n",
      "Loss after 400/439 Batch is 1.1005859375 \n",
      "Combined Loss Value after 4 Epoch is 1.0945330296127562\n",
      "Starting Epoch 5 ------------------------------------------\n",
      "Loss after 0/439 Batch is 1.009765625 \n",
      "Loss after 100/439 Batch is 1.0703125 \n",
      "Loss after 200/439 Batch is 1.064453125 \n",
      "Loss after 300/439 Batch is 1.0517578125 \n",
      "Loss after 400/439 Batch is 1.0458984375 \n",
      "Combined Loss Value after 5 Epoch is 1.042141230068337\n",
      "Starting Epoch 6 ------------------------------------------\n",
      "Loss after 0/439 Batch is 1.0986328125 \n",
      "Loss after 100/439 Batch is 1.021484375 \n",
      "Loss after 200/439 Batch is 1.0166015625 \n",
      "Loss after 300/439 Batch is 1.013671875 \n",
      "Loss after 400/439 Batch is 1.009765625 \n",
      "Combined Loss Value after 6 Epoch is 1.0085421412300684\n",
      "Starting Epoch 7 ------------------------------------------\n",
      "Loss after 0/439 Batch is 0.98193359375 \n",
      "Loss after 100/439 Batch is 0.99072265625 \n",
      "Loss after 200/439 Batch is 0.9833984375 \n",
      "Loss after 300/439 Batch is 0.984375 \n",
      "Loss after 400/439 Batch is 0.98681640625 \n",
      "Combined Loss Value after 7 Epoch is 0.9857630979498861\n",
      "Starting Epoch 8 ------------------------------------------\n",
      "Loss after 0/439 Batch is 1.005859375 \n",
      "Loss after 100/439 Batch is 0.95361328125 \n",
      "Loss after 200/439 Batch is 0.958984375 \n",
      "Loss after 300/439 Batch is 0.96240234375 \n",
      "Loss after 400/439 Batch is 0.9677734375 \n",
      "Combined Loss Value after 8 Epoch is 0.9698177676537585\n",
      "Starting Epoch 9 ------------------------------------------\n",
      "Loss after 0/439 Batch is 0.921875 \n",
      "Loss after 100/439 Batch is 0.94140625 \n",
      "Loss after 200/439 Batch is 0.9296875 \n",
      "Loss after 300/439 Batch is 0.93603515625 \n",
      "Loss after 400/439 Batch is 0.94091796875 \n",
      "Combined Loss Value after 9 Epoch is 0.9419134396355353\n",
      "Starting Epoch 10 ------------------------------------------\n",
      "Loss after 0/439 Batch is 0.87353515625 \n",
      "Loss after 100/439 Batch is 0.91748046875 \n",
      "Loss after 200/439 Batch is 0.9189453125 \n",
      "Loss after 300/439 Batch is 0.92041015625 \n",
      "Loss after 400/439 Batch is 0.923828125 \n",
      "Combined Loss Value after 10 Epoch is 0.9225512528473804\n",
      "Starting Epoch 11 ------------------------------------------\n",
      "Loss after 0/439 Batch is 1.126953125 \n",
      "Loss after 100/439 Batch is 0.92333984375 \n",
      "Loss after 200/439 Batch is 0.91357421875 \n",
      "Loss after 300/439 Batch is 0.90673828125 \n",
      "Loss after 400/439 Batch is 0.91064453125 \n",
      "Combined Loss Value after 11 Epoch is 0.9105922551252847\n",
      "Starting Epoch 12 ------------------------------------------\n",
      "Loss after 0/439 Batch is 0.890625 \n",
      "Loss after 100/439 Batch is 0.89990234375 \n",
      "Loss after 200/439 Batch is 0.8916015625 \n",
      "Loss after 300/439 Batch is 0.8955078125 \n",
      "Loss after 400/439 Batch is 0.89013671875 \n",
      "Combined Loss Value after 12 Epoch is 0.8895216400911162\n",
      "Starting Epoch 13 ------------------------------------------\n",
      "Loss after 0/439 Batch is 0.8388671875 \n",
      "Loss after 100/439 Batch is 0.8935546875 \n",
      "Loss after 200/439 Batch is 0.88427734375 \n",
      "Loss after 300/439 Batch is 0.87939453125 \n",
      "Loss after 400/439 Batch is 0.88330078125 \n",
      "Combined Loss Value after 13 Epoch is 0.8821184510250569\n",
      "Starting Epoch 14 ------------------------------------------\n",
      "Loss after 0/439 Batch is 0.82275390625 \n",
      "Loss after 100/439 Batch is 0.8798828125 \n",
      "Loss after 200/439 Batch is 0.87255859375 \n",
      "Loss after 300/439 Batch is 0.87109375 \n",
      "Loss after 400/439 Batch is 0.869140625 \n",
      "Combined Loss Value after 14 Epoch is 0.8633257403189066\n",
      "Starting Epoch 15 ------------------------------------------\n",
      "Loss after 0/439 Batch is 0.8310546875 \n",
      "Loss after 100/439 Batch is 0.8720703125 \n",
      "Loss after 200/439 Batch is 0.8720703125 \n",
      "Loss after 300/439 Batch is 0.8662109375 \n",
      "Loss after 400/439 Batch is 0.865234375 \n",
      "Combined Loss Value after 15 Epoch is 0.8661731207289294\n",
      "Starting Epoch 16 ------------------------------------------\n",
      "Loss after 0/439 Batch is 0.97509765625 \n",
      "Loss after 100/439 Batch is 0.86279296875 \n",
      "Loss after 200/439 Batch is 0.861328125 \n",
      "Loss after 300/439 Batch is 0.85791015625 \n",
      "Loss after 400/439 Batch is 0.8515625 \n",
      "Combined Loss Value after 16 Epoch is 0.8479498861047836\n",
      "Starting Epoch 17 ------------------------------------------\n",
      "Loss after 0/439 Batch is 0.791015625 \n",
      "Loss after 100/439 Batch is 0.841796875 \n",
      "Loss after 200/439 Batch is 0.84814453125 \n",
      "Loss after 300/439 Batch is 0.85009765625 \n",
      "Loss after 400/439 Batch is 0.83642578125 \n",
      "Combined Loss Value after 17 Epoch is 0.8348519362186788\n",
      "Starting Epoch 18 ------------------------------------------\n",
      "Loss after 0/439 Batch is 0.91552734375 \n",
      "Loss after 100/439 Batch is 0.84033203125 \n",
      "Loss after 200/439 Batch is 0.8427734375 \n",
      "Loss after 300/439 Batch is 0.8408203125 \n",
      "Loss after 400/439 Batch is 0.83251953125 \n",
      "Combined Loss Value after 18 Epoch is 0.8297266514806378\n",
      "Starting Epoch 19 ------------------------------------------\n",
      "Loss after 0/439 Batch is 0.83447265625 \n",
      "Loss after 100/439 Batch is 0.841796875 \n",
      "Loss after 200/439 Batch is 0.8388671875 \n",
      "Loss after 300/439 Batch is 0.83740234375 \n",
      "Loss after 400/439 Batch is 0.82421875 \n",
      "Combined Loss Value after 19 Epoch is 0.821753986332574\n",
      "Starting Epoch 20 ------------------------------------------\n",
      "Loss after 0/439 Batch is 0.92431640625 \n",
      "Loss after 100/439 Batch is 0.826171875 \n",
      "Loss after 200/439 Batch is 0.82763671875 \n",
      "Loss after 300/439 Batch is 0.826171875 \n",
      "Loss after 400/439 Batch is 0.8203125 \n",
      "Combined Loss Value after 20 Epoch is 0.816628701594533\n",
      "Starting Epoch 21 ------------------------------------------\n",
      "Loss after 0/439 Batch is 0.86572265625 \n",
      "Loss after 100/439 Batch is 0.82666015625 \n",
      "Loss after 200/439 Batch is 0.82568359375 \n",
      "Loss after 300/439 Batch is 0.8251953125 \n",
      "Loss after 400/439 Batch is 0.81494140625 \n",
      "Combined Loss Value after 21 Epoch is 0.8115034168564921\n",
      "Starting Epoch 22 ------------------------------------------\n",
      "Loss after 0/439 Batch is 0.8330078125 \n",
      "Loss after 100/439 Batch is 0.8173828125 \n",
      "Loss after 200/439 Batch is 0.81982421875 \n",
      "Loss after 300/439 Batch is 0.81787109375 \n",
      "Loss after 400/439 Batch is 0.80908203125 \n",
      "Combined Loss Value after 22 Epoch is 0.8069476082004556\n",
      "Starting Epoch 23 ------------------------------------------\n",
      "Loss after 0/439 Batch is 0.796875 \n",
      "Loss after 100/439 Batch is 0.810546875 \n",
      "Loss after 200/439 Batch is 0.81201171875 \n",
      "Loss after 300/439 Batch is 0.81396484375 \n",
      "Loss after 400/439 Batch is 0.806640625 \n",
      "Combined Loss Value after 23 Epoch is 0.8052391799544419\n",
      "Starting Epoch 24 ------------------------------------------\n",
      "Loss after 0/439 Batch is 0.8359375 \n",
      "Loss after 100/439 Batch is 0.81103515625 \n",
      "Loss after 200/439 Batch is 0.80615234375 \n",
      "Loss after 300/439 Batch is 0.8046875 \n",
      "Loss after 400/439 Batch is 0.7998046875 \n",
      "Combined Loss Value after 24 Epoch is 0.7972665148063781\n",
      "Starting Epoch 25 ------------------------------------------\n",
      "Loss after 0/439 Batch is 0.8623046875 \n",
      "Loss after 100/439 Batch is 0.7978515625 \n",
      "Loss after 200/439 Batch is 0.7958984375 \n",
      "Loss after 300/439 Batch is 0.7958984375 \n",
      "Loss after 400/439 Batch is 0.791015625 \n",
      "Combined Loss Value after 25 Epoch is 0.7892938496583144\n",
      "Starting Epoch 26 ------------------------------------------\n",
      "Loss after 0/439 Batch is 0.69384765625 \n",
      "Loss after 100/439 Batch is 0.79931640625 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 200/439 Batch is 0.79833984375 \n",
      "Loss after 300/439 Batch is 0.79638671875 \n",
      "Loss after 400/439 Batch is 0.7900390625 \n",
      "Combined Loss Value after 26 Epoch is 0.7864464692482915\n",
      "Starting Epoch 27 ------------------------------------------\n",
      "Loss after 0/439 Batch is 0.79345703125 \n",
      "Loss after 100/439 Batch is 0.783203125 \n",
      "Loss after 200/439 Batch is 0.79052734375 \n",
      "Loss after 300/439 Batch is 0.79296875 \n",
      "Loss after 400/439 Batch is 0.78662109375 \n",
      "Combined Loss Value after 27 Epoch is 0.7835990888382688\n",
      "Starting Epoch 28 ------------------------------------------\n",
      "Loss after 0/439 Batch is 0.86572265625 \n",
      "Loss after 100/439 Batch is 0.796875 \n",
      "Loss after 200/439 Batch is 0.791015625 \n",
      "Loss after 300/439 Batch is 0.78759765625 \n",
      "Loss after 400/439 Batch is 0.78125 \n",
      "Combined Loss Value after 28 Epoch is 0.7790432801822323\n",
      "Starting Epoch 29 ------------------------------------------\n",
      "Loss after 0/439 Batch is 0.8515625 \n",
      "Loss after 100/439 Batch is 0.79150390625 \n",
      "Loss after 200/439 Batch is 0.78369140625 \n",
      "Loss after 300/439 Batch is 0.78173828125 \n",
      "Loss after 400/439 Batch is 0.77734375 \n",
      "Combined Loss Value after 29 Epoch is 0.775626423690205\n",
      "Starting Epoch 30 ------------------------------------------\n",
      "Loss after 0/439 Batch is 0.79833984375 \n",
      "Loss after 100/439 Batch is 0.791015625 \n",
      "Loss after 200/439 Batch is 0.78369140625 \n",
      "Loss after 300/439 Batch is 0.78369140625 \n",
      "Loss after 400/439 Batch is 0.77880859375 \n",
      "Combined Loss Value after 30 Epoch is 0.775626423690205\n"
     ]
    }
   ],
   "source": [
    "Trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a3c9953",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "format_data = \"date_%d_%m_%y_time_%H_%M_%S\"\n",
    "timestamp = datetime.strftime(datetime.now(), format_data)\n",
    "\n",
    "torch.save(\n",
    "    Trainer.visual_student.state_dict(),\n",
    "    f\"results/{timestamp}_{loss_name}_CombinedVisual_DistilledModel.pt\",\n",
    ")\n",
    "torch.save(\n",
    "    Trainer.text_student.state_dict(),\n",
    "    f\"results/{timestamp}_{loss_name}_CombinedText_DistilledModel.pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "879df765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/date_08_12_22_time_04_47_47_loss2_CombinedVisual_DistilledModel.pt\n"
     ]
    }
   ],
   "source": [
    "print(f\"results/{timestamp}_{loss_name}_CombinedVisual_DistilledModel.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797059c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
