{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87273e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from datetime import datetime\n",
    "from typing import Tuple\n",
    "from torch import nn\n",
    "from torch.nn import Module\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import KLDivLoss, CrossEntropyLoss, CosineEmbeddingLoss, MSELoss\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f93f1c",
   "metadata": {},
   "source": [
    "### Combined Image and TextDistillation with Bigger Dataset with Loss3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b783395",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_name = \"loss3\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9bd6d6",
   "metadata": {},
   "source": [
    "#### Loading Teacher models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88cbfadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "\n",
    "model_name = \"ViT-B/32\"\n",
    "\n",
    "# model is the torch model.\n",
    "# preprocess function is for image preprocessing.\n",
    "\n",
    "model, preprocess = clip.load(model_name)\n",
    "\n",
    "# Get only the visual model\n",
    "visual_teacher_model = model.visual\n",
    "text_teacher_model = model.transformer\n",
    "\n",
    "\n",
    "input_resolution = model.visual.input_resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7896653c",
   "metadata": {},
   "source": [
    "### Instantiating Student models\n",
    "\n",
    "[VisionTransformer](https://github.com/openai/CLIP/blob/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1/clip/model.py#L206)\n",
    "[Transformer](https://github.com/openai/CLIP/blob/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1/clip/model.py#L195)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1340820",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clip.model import Transformer, VisionTransformer\n",
    "from clip.model import convert_weights  # Make them float16\n",
    "\n",
    "# Set Student Configuration\n",
    "\n",
    "patch_size = 32\n",
    "width = 384\n",
    "layers = 6\n",
    "heads = 12\n",
    "output_dim = 512\n",
    "\n",
    "visual_student_model = VisionTransformer(\n",
    "    input_resolution=input_resolution,\n",
    "    patch_size=patch_size,\n",
    "    width=width,\n",
    "    layers=layers,\n",
    "    heads=heads,\n",
    "    output_dim=output_dim,\n",
    ")\n",
    "\n",
    "width = 512\n",
    "layers = 6\n",
    "heads = 8  # More Number of Heads\n",
    "\n",
    "\n",
    "def build_attention_mask():\n",
    "    context_length = 77\n",
    "    mask = torch.empty(context_length, context_length)\n",
    "    mask.fill_(float(\"-inf\"))\n",
    "    mask.triu_(1)  # zero out the lower diagonal\n",
    "    return mask\n",
    "\n",
    "\n",
    "text_student_model = Transformer(\n",
    "    width=width, layers=layers, heads=heads, attn_mask=build_attention_mask()\n",
    ")\n",
    "\n",
    "\n",
    "convert_weights(visual_student_model)\n",
    "convert_weights(text_student_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c600678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_text(transformer, text):\n",
    "\n",
    "    x = model.token_embedding(text).type(model.dtype)  # [batch_size, n_ctx, d_model]\n",
    "\n",
    "    x = x + model.positional_embedding.type(model.dtype)\n",
    "    x = x.permute(1, 0, 2)  # NLD -> LND\n",
    "\n",
    "    x = transformer(x)\n",
    "\n",
    "    x = x.permute(1, 0, 2)  # LND -> NLD\n",
    "    x = model.ln_final(x).type(model.dtype)\n",
    "\n",
    "    # x.shape = [batch_size, n_ctx, transformer.width]\n",
    "    # take features from the eot embedding (eot_token is the highest number in each sequence)\n",
    "    x = x[torch.arange(x.shape[0]), text.argmax(dim=-1)] @ model.text_projection\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c4d724e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProjectionHead(nn.Module):\n",
    "    def __init__(self, embedding_dim=512, projection_dim=512, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.projection = nn.Linear(embedding_dim, projection_dim)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.fc = nn.Linear(projection_dim, projection_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(projection_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        projected = self.projection(x)\n",
    "        x = self.gelu(projected)\n",
    "        x = self.fc(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x + projected\n",
    "        x = self.layer_norm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6debb0c",
   "metadata": {},
   "source": [
    "### Load the WIT Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0948606c",
   "metadata": {},
   "source": [
    "### Convert Dataset into Torch Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0ef402f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_from_disk\n",
    "\n",
    "dset = load_from_disk(\"./data/processed\")\n",
    "\n",
    "\n",
    "def transform_func(examples):\n",
    "    examples[\"image\"] = [preprocess(img) for img in examples[\"image\"]]\n",
    "    return examples\n",
    "\n",
    "\n",
    "dset = dset.with_transform(transform_func)\n",
    "\n",
    "train_dataloader = DataLoader(dset, batch_size=16, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db4ba5e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['caption', 'image'],\n",
       "    num_rows: 7012\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "609fd86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistillationTrainer:\n",
    "    def __init__(self, *args, **kwargs):\n",
    "\n",
    "        self.visual_teacher = visual_teacher_model\n",
    "        self.text_teacher = text_teacher_model\n",
    "\n",
    "        self.visual_student = visual_student_model\n",
    "        self.text_student = text_student_model\n",
    "\n",
    "        self.image_projection = ProjectionHead().half()\n",
    "        self.text_projection = ProjectionHead().half()\n",
    "        self.temperature = 1\n",
    "\n",
    "        self.train_dataloader = train_dataloader\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.visual_teacher = self.visual_teacher.to(self.device)\n",
    "        self.text_teacher = self.text_teacher.to(self.device)\n",
    "        self.visual_student = self.visual_student.to(self.device)\n",
    "        self.text_student = self.text_student.to(self.device)\n",
    "        self.image_projection = self.image_projection.to(self.device)\n",
    "        self.text_projection = self.text_projection.to(self.device)\n",
    "\n",
    "        self.visual_teacher.eval()\n",
    "        self.text_teacher.eval()\n",
    "\n",
    "        self.epochs = 30\n",
    "        self.start_epoch = 1\n",
    "\n",
    "        # set up optimizer\n",
    "        self.optimizer = SGD(\n",
    "            list(self.visual_student.parameters())\n",
    "            + list(self.text_student.parameters()),\n",
    "            lr=0.001,\n",
    "        )\n",
    "\n",
    "    def compute_loss(self, images, texts, return_outputs=False):\n",
    "        texts = clip.tokenize(texts)\n",
    "\n",
    "        texts = texts.to(self.device)\n",
    "\n",
    "        images = images.to(self.device).half()\n",
    "\n",
    "        visual_outputs_student = self.visual_student(images)\n",
    "        text_outputs_student = encode_text(self.text_student, texts)\n",
    "\n",
    "        # compute teacher output\n",
    "        with torch.no_grad():\n",
    "            visual_outputs_teacher = self.visual_teacher(images)\n",
    "            text_outputs_teacher = model.encode_text(texts)\n",
    "\n",
    "        # assert size\n",
    "        assert visual_outputs_student.size() == visual_outputs_teacher.size()\n",
    "        assert text_outputs_student.size() == text_outputs_teacher.size()\n",
    "\n",
    "        # Get the image and text embeddings\n",
    "\n",
    "        image_embeddings = self.image_projection(visual_outputs_teacher)\n",
    "        text_embeddings = self.text_projection(text_outputs_teacher)\n",
    "        teacher_logits = (text_embeddings @ image_embeddings.T) / self.temperature\n",
    "\n",
    "        image_embeddings = self.image_projection(visual_outputs_student)\n",
    "        text_embeddings = self.text_projection(text_outputs_student)\n",
    "        logits = (text_embeddings @ image_embeddings.T) / self.temperature\n",
    "\n",
    "        # KL Divergence Loss between logits of teacher and student\n",
    "\n",
    "        kl_loss = KLDivLoss(reduction=\"batchmean\", log_target=True)\n",
    "\n",
    "        logits_kl_loss = kl_loss(F.log_softmax(teacher_logits), F.log_softmax(logits))\n",
    "\n",
    "        # Push visual_outputs_student and text_outputs_student closer\n",
    "\n",
    "        images_similarity = image_embeddings @ image_embeddings.T\n",
    "        texts_similarity = text_embeddings @ text_embeddings.T\n",
    "\n",
    "        targets = F.softmax(\n",
    "            (images_similarity + texts_similarity) / 2 * self.temperature, dim=-1\n",
    "        )\n",
    "\n",
    "        texts_loss = self.cross_entropy(logits, targets, reduction=\"none\")\n",
    "        images_loss = self.cross_entropy(logits.T, targets.T, reduction=\"none\")\n",
    "        con_loss = (images_loss + texts_loss) / 2.0\n",
    "        con_loss = con_loss.mean()\n",
    "\n",
    "        loss = (logits_kl_loss + con_loss) / 2\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def cross_entropy(self, preds, targets, reduction=\"none\"):\n",
    "        log_softmax = nn.LogSoftmax(dim=-1)\n",
    "        loss = (-targets * log_softmax(preds)).sum(1)\n",
    "        if reduction == \"none\":\n",
    "            return loss\n",
    "        elif reduction == \"mean\":\n",
    "            return loss.mean()\n",
    "\n",
    "    def train(self):\n",
    "        for epoch in range(self.start_epoch, self.epochs + 1):\n",
    "            print(f\"Starting Epoch {epoch} ------------------------------------------\")\n",
    "            loss_value = self._train_epoch(epoch)\n",
    "            print(f\"Combined Loss Value after {epoch} Epoch is {loss_value}\")\n",
    "\n",
    "    def _train_epoch(self, epoch):\n",
    "        loss_value = 0\n",
    "        for batch_idx, data in enumerate(self.train_dataloader):\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            texts = data[\"caption\"]\n",
    "            images = data[\"image\"]\n",
    "\n",
    "            loss = self.compute_loss(images, texts)\n",
    "\n",
    "            loss_value += loss\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            self.optimizer.step()\n",
    "\n",
    "            if batch_idx % 100 == 0:\n",
    "                print(\n",
    "                    f\"Loss after {batch_idx}/{len(self.train_dataloader)} Batch is {loss_value/(batch_idx+1)} \"\n",
    "                )\n",
    "\n",
    "        return loss_value.detach().cpu().numpy() / len(self.train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63c467ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Trainer = DistillationTrainer(\n",
    "    visual_teacher_model=visual_teacher_model,\n",
    "    text_teacher_model=text_teacher_model,\n",
    "    text_student_model=text_student_model,\n",
    "    visual_student_model=visual_student_model,\n",
    "    train_dataloader=train_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c83373ae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1 ------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ecbm4040/envTF24/lib/python3.6/site-packages/ipykernel_launcher.py:70: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 0/439 Batch is 21.609375 \n",
      "Loss after 100/439 Batch is 24.75 \n",
      "Loss after 200/439 Batch is 22.328125 \n",
      "Loss after 300/439 Batch is 21.625 \n",
      "Loss after 400/439 Batch is 21.25 \n",
      "Combined Loss Value after 1 Epoch is 20.9749430523918\n",
      "Starting Epoch 2 ------------------------------------------\n",
      "Loss after 0/439 Batch is 14.9375 \n",
      "Loss after 100/439 Batch is 17.875 \n",
      "Loss after 200/439 Batch is 17.671875 \n",
      "Loss after 300/439 Batch is 17.25 \n",
      "Loss after 400/439 Batch is 17.203125 \n",
      "Combined Loss Value after 2 Epoch is 17.047835990888384\n",
      "Starting Epoch 3 ------------------------------------------\n",
      "Loss after 0/439 Batch is 6.7421875 \n",
      "Loss after 100/439 Batch is 15.421875 \n",
      "Loss after 200/439 Batch is 15.515625 \n",
      "Loss after 300/439 Batch is 15.75 \n",
      "Loss after 400/439 Batch is 15.7890625 \n",
      "Combined Loss Value after 3 Epoch is 15.854214123006834\n",
      "Starting Epoch 4 ------------------------------------------\n",
      "Loss after 0/439 Batch is 19.09375 \n",
      "Loss after 100/439 Batch is 15.109375 \n",
      "Loss after 200/439 Batch is 15.375 \n",
      "Loss after 300/439 Batch is 15.2578125 \n",
      "Loss after 400/439 Batch is 15.1328125 \n",
      "Combined Loss Value after 4 Epoch is 15.15261958997722\n",
      "Starting Epoch 5 ------------------------------------------\n",
      "Loss after 0/439 Batch is 34.40625 \n",
      "Loss after 100/439 Batch is 14.65625 \n",
      "Loss after 200/439 Batch is 14.5 \n",
      "Loss after 300/439 Batch is 14.7265625 \n",
      "Loss after 400/439 Batch is 14.7265625 \n",
      "Combined Loss Value after 5 Epoch is 14.724373576309794\n",
      "Starting Epoch 6 ------------------------------------------\n",
      "Loss after 0/439 Batch is 18.3125 \n",
      "Loss after 100/439 Batch is 13.3203125 \n",
      "Loss after 200/439 Batch is 14.2265625 \n",
      "Loss after 300/439 Batch is 13.875 \n",
      "Loss after 400/439 Batch is 13.875 \n",
      "Combined Loss Value after 6 Epoch is 13.85876993166287\n",
      "Starting Epoch 7 ------------------------------------------\n",
      "Loss after 0/439 Batch is 16.140625 \n",
      "Loss after 100/439 Batch is 13.3203125 \n",
      "Loss after 200/439 Batch is 12.8671875 \n",
      "Loss after 300/439 Batch is 13.09375 \n",
      "Loss after 400/439 Batch is 13.2734375 \n",
      "Combined Loss Value after 7 Epoch is 13.38496583143508\n",
      "Starting Epoch 8 ------------------------------------------\n",
      "Loss after 0/439 Batch is 8.0625 \n",
      "Loss after 100/439 Batch is 13.3828125 \n",
      "Loss after 200/439 Batch is 13.1875 \n",
      "Loss after 300/439 Batch is 13.046875 \n",
      "Loss after 400/439 Batch is 13.1484375 \n",
      "Combined Loss Value after 8 Epoch is 13.12984054669704\n",
      "Starting Epoch 9 ------------------------------------------\n",
      "Loss after 0/439 Batch is 13.3125 \n",
      "Loss after 100/439 Batch is 13.40625 \n",
      "Loss after 200/439 Batch is 13.375 \n",
      "Loss after 300/439 Batch is 13.1328125 \n",
      "Loss after 400/439 Batch is 13.140625 \n",
      "Combined Loss Value after 9 Epoch is 13.138952164009112\n",
      "Starting Epoch 10 ------------------------------------------\n",
      "Loss after 0/439 Batch is 13.375 \n",
      "Loss after 100/439 Batch is 12.4375 \n",
      "Loss after 200/439 Batch is 12.640625 \n",
      "Loss after 300/439 Batch is 12.8671875 \n",
      "Loss after 400/439 Batch is 12.78125 \n",
      "Combined Loss Value after 10 Epoch is 12.865603644646924\n",
      "Starting Epoch 11 ------------------------------------------\n",
      "Loss after 0/439 Batch is 21.765625 \n",
      "Loss after 100/439 Batch is 13.0 \n",
      "Loss after 200/439 Batch is 12.8046875 \n",
      "Loss after 300/439 Batch is 12.921875 \n",
      "Loss after 400/439 Batch is 12.8203125 \n",
      "Combined Loss Value after 11 Epoch is 12.701594533029613\n",
      "Starting Epoch 12 ------------------------------------------\n",
      "Loss after 0/439 Batch is 16.21875 \n",
      "Loss after 100/439 Batch is 12.4921875 \n",
      "Loss after 200/439 Batch is 12.484375 \n",
      "Loss after 300/439 Batch is 12.5078125 \n",
      "Loss after 400/439 Batch is 12.4375 \n",
      "Combined Loss Value after 12 Epoch is 12.455580865603645\n",
      "Starting Epoch 13 ------------------------------------------\n",
      "Loss after 0/439 Batch is 12.6875 \n",
      "Loss after 100/439 Batch is 12.5546875 \n",
      "Loss after 200/439 Batch is 12.8359375 \n",
      "Loss after 300/439 Batch is 12.953125 \n",
      "Loss after 400/439 Batch is 12.65625 \n",
      "Combined Loss Value after 13 Epoch is 12.69248291571754\n",
      "Starting Epoch 14 ------------------------------------------\n",
      "Loss after 0/439 Batch is 5.88671875 \n",
      "Loss after 100/439 Batch is 13.4140625 \n",
      "Loss after 200/439 Batch is 12.765625 \n",
      "Loss after 300/439 Batch is 12.765625 \n",
      "Loss after 400/439 Batch is 12.875 \n",
      "Combined Loss Value after 14 Epoch is 12.738041002277905\n",
      "Starting Epoch 15 ------------------------------------------\n",
      "Loss after 0/439 Batch is 12.0078125 \n",
      "Loss after 100/439 Batch is 11.9921875 \n",
      "Loss after 200/439 Batch is 11.8984375 \n",
      "Loss after 300/439 Batch is 12.0 \n",
      "Loss after 400/439 Batch is 12.3671875 \n",
      "Combined Loss Value after 15 Epoch is 12.337129840546696\n",
      "Starting Epoch 16 ------------------------------------------\n",
      "Loss after 0/439 Batch is 13.6015625 \n",
      "Loss after 100/439 Batch is 11.953125 \n",
      "Loss after 200/439 Batch is 12.59375 \n",
      "Loss after 300/439 Batch is 12.375 \n",
      "Loss after 400/439 Batch is 12.3203125 \n",
      "Combined Loss Value after 16 Epoch is 12.300683371298405\n",
      "Starting Epoch 17 ------------------------------------------\n",
      "Loss after 0/439 Batch is 19.75 \n",
      "Loss after 100/439 Batch is 11.5859375 \n",
      "Loss after 200/439 Batch is 12.1875 \n",
      "Loss after 300/439 Batch is 12.15625 \n",
      "Loss after 400/439 Batch is 12.265625 \n",
      "Combined Loss Value after 17 Epoch is 12.300683371298405\n",
      "Starting Epoch 18 ------------------------------------------\n",
      "Loss after 0/439 Batch is 5.78125 \n",
      "Loss after 100/439 Batch is 12.328125 \n",
      "Loss after 200/439 Batch is 11.9296875 \n",
      "Loss after 300/439 Batch is 11.875 \n",
      "Loss after 400/439 Batch is 11.953125 \n",
      "Combined Loss Value after 18 Epoch is 11.890660592255125\n",
      "Starting Epoch 19 ------------------------------------------\n",
      "Loss after 0/439 Batch is 8.609375 \n",
      "Loss after 100/439 Batch is 12.7421875 \n",
      "Loss after 200/439 Batch is 12.4609375 \n",
      "Loss after 300/439 Batch is 12.203125 \n",
      "Loss after 400/439 Batch is 12.203125 \n",
      "Combined Loss Value after 19 Epoch is 12.154897494305239\n",
      "Starting Epoch 20 ------------------------------------------\n",
      "Loss after 0/439 Batch is 11.8359375 \n",
      "Loss after 100/439 Batch is 11.0234375 \n",
      "Loss after 200/439 Batch is 11.34375 \n",
      "Loss after 300/439 Batch is 11.53125 \n",
      "Loss after 400/439 Batch is 11.4609375 \n",
      "Combined Loss Value after 20 Epoch is 11.453302961275627\n",
      "Starting Epoch 21 ------------------------------------------\n",
      "Loss after 0/439 Batch is 12.8984375 \n",
      "Loss after 100/439 Batch is 11.6640625 \n",
      "Loss after 200/439 Batch is 11.8984375 \n",
      "Loss after 300/439 Batch is 11.78125 \n",
      "Loss after 400/439 Batch is 11.9296875 \n",
      "Combined Loss Value after 21 Epoch is 11.945330296127562\n",
      "Starting Epoch 22 ------------------------------------------\n",
      "Loss after 0/439 Batch is 17.25 \n",
      "Loss after 100/439 Batch is 11.5625 \n",
      "Loss after 200/439 Batch is 11.9140625 \n",
      "Loss after 300/439 Batch is 12.0078125 \n",
      "Loss after 400/439 Batch is 12.0390625 \n",
      "Combined Loss Value after 22 Epoch is 12.045558086560364\n",
      "Starting Epoch 23 ------------------------------------------\n",
      "Loss after 0/439 Batch is 22.578125 \n",
      "Loss after 100/439 Batch is 11.75 \n",
      "Loss after 200/439 Batch is 11.5703125 \n",
      "Loss after 300/439 Batch is 11.703125 \n",
      "Loss after 400/439 Batch is 11.6328125 \n",
      "Combined Loss Value after 23 Epoch is 11.708428246013668\n",
      "Starting Epoch 24 ------------------------------------------\n",
      "Loss after 0/439 Batch is 12.640625 \n",
      "Loss after 100/439 Batch is 11.859375 \n",
      "Loss after 200/439 Batch is 11.609375 \n",
      "Loss after 300/439 Batch is 11.5234375 \n",
      "Loss after 400/439 Batch is 11.71875 \n",
      "Combined Loss Value after 24 Epoch is 11.763097949886104\n",
      "Starting Epoch 25 ------------------------------------------\n",
      "Loss after 0/439 Batch is 16.703125 \n",
      "Loss after 100/439 Batch is 11.3828125 \n",
      "Loss after 200/439 Batch is 11.1328125 \n",
      "Loss after 300/439 Batch is 11.28125 \n",
      "Loss after 400/439 Batch is 11.2421875 \n",
      "Combined Loss Value after 25 Epoch is 11.24373576309795\n",
      "Starting Epoch 26 ------------------------------------------\n",
      "Loss after 0/439 Batch is 10.84375 \n",
      "Loss after 100/439 Batch is 10.8125 \n",
      "Loss after 200/439 Batch is 10.9765625 \n",
      "Loss after 300/439 Batch is 11.1796875 \n",
      "Loss after 400/439 Batch is 11.265625 \n",
      "Combined Loss Value after 26 Epoch is 11.161731207289295\n",
      "Starting Epoch 27 ------------------------------------------\n",
      "Loss after 0/439 Batch is 11.65625 \n",
      "Loss after 100/439 Batch is 10.8984375 \n",
      "Loss after 200/439 Batch is 11.1171875 \n",
      "Loss after 300/439 Batch is 11.40625 \n",
      "Loss after 400/439 Batch is 11.2109375 \n",
      "Combined Loss Value after 27 Epoch is 11.207289293849659\n",
      "Starting Epoch 28 ------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 0/439 Batch is 8.875 \n",
      "Loss after 100/439 Batch is 10.75 \n",
      "Loss after 200/439 Batch is 10.796875 \n",
      "Loss after 300/439 Batch is 11.015625 \n",
      "Loss after 400/439 Batch is 10.8203125 \n",
      "Combined Loss Value after 28 Epoch is 10.76993166287016\n",
      "Starting Epoch 29 ------------------------------------------\n",
      "Loss after 0/439 Batch is 9.734375 \n",
      "Loss after 100/439 Batch is 11.0 \n",
      "Loss after 200/439 Batch is 10.65625 \n",
      "Loss after 300/439 Batch is 10.65625 \n",
      "Loss after 400/439 Batch is 10.796875 \n",
      "Combined Loss Value after 29 Epoch is 10.788154897494305\n",
      "Starting Epoch 30 ------------------------------------------\n",
      "Loss after 0/439 Batch is 9.2578125 \n",
      "Loss after 100/439 Batch is 10.640625 \n",
      "Loss after 200/439 Batch is 11.0859375 \n",
      "Loss after 300/439 Batch is 10.984375 \n",
      "Loss after 400/439 Batch is 10.8046875 \n",
      "Combined Loss Value after 30 Epoch is 10.751708428246014\n"
     ]
    }
   ],
   "source": [
    "Trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a3c9953",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "format_data = \"date_%d_%m_%y_time_%H_%M_%S\"\n",
    "timestamp = datetime.strftime(datetime.now(), format_data)\n",
    "\n",
    "torch.save(\n",
    "    Trainer.visual_student.state_dict(),\n",
    "    f\"results/{timestamp}_{loss_name}_CombinedVisual_DistilledModel.pt\",\n",
    ")\n",
    "torch.save(\n",
    "    Trainer.text_student.state_dict(),\n",
    "    f\"results/{timestamp}_{loss_name}_CombinedText_DistilledModel.pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e60226",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
